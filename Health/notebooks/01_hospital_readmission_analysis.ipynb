{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hospital Readmission Prediction – End-to-End Healthcare Analytics\n",
        "\n",
        "This notebook walks through a complete **Hospital Readmission Prediction** project: from business context to model evaluation and deployment considerations, using Python and Scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Business Problem Understanding\n",
        "\n",
        "### Why hospital readmission matters\n",
        "- **Quality of care**: Readmissions within 30 days often indicate inadequate discharge planning, follow-up, or patient understanding.\n",
        "- **Patient outcomes**: Repeated hospitalizations increase risk of complications and reduce quality of life.\n",
        "- **Regulatory**: In many countries (e.g., US HRRP), hospitals are penalized for excess readmissions.\n",
        "\n",
        "### Cost impact\n",
        "- Unplanned readmissions are expensive (e.g., $15–20K+ per readmission in the US).\n",
        "- Medicare and other payers may reduce reimbursement for high readmission rates.\n",
        "- Proactive interventions (care coordination, follow-up) are cheaper than readmissions.\n",
        "\n",
        "### Healthcare operational efficiency\n",
        "- Identifying high-risk patients allows targeted discharge planning and transitional care.\n",
        "- Better bed utilization and scheduling when readmission risk is factored in.\n",
        "- Data-driven prioritization of case management and follow-up calls."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Dataset Description\n",
        "\n",
        "We use a synthetic dataset that mirrors real-world structure:\n",
        "\n",
        "| Category | Variables | Description |\n",
        "|----------|-----------|-------------|\n",
        "| **Patient demographics** | age, gender, race | Age group, sex, race/ethnicity |\n",
        "| **Medical history** | number_outpatient, number_emergency, number_inpatient | Prior utilization |\n",
        "| **Admission details** | admission_type, admission_source, discharge_disposition, time_in_hospital, admission_date | Type of stay and length |\n",
        "| **Lab / procedures** | num_lab_procedures, num_procedures, num_medications, max_glu_serum, A1Cresult | Labs and meds |\n",
        "| **Diagnosis** | diag_1, diag_2, diag_3, number_diagnoses | Primary/secondary diagnoses |\n",
        "| **Chronic conditions** | diabetes, hypertension, chronic_kidney_disease, heart_failure | Binary indicators |\n",
        "| **Target** | readmitted | 1 = readmitted within 30 days, 0 = not readmitted |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
        "DATA_PATH = PROJECT_ROOT / 'data' / 'hospital_readmission.csv'\n",
        "\n",
        "if not DATA_PATH.exists():\n",
        "    sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
        "    from generate_data import generate_synthetic_readmission_data\n",
        "    (PROJECT_ROOT / 'data').mkdir(exist_ok=True)\n",
        "    df_raw = generate_synthetic_readmission_data()\n",
        "    df_raw.to_csv(DATA_PATH, index=False)\n",
        "    print('Generated synthetic data at', DATA_PATH)\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print('Shape:', df.shape)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n",
        "df.describe(include='all').T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Data Cleaning\n",
        "\n",
        "- Handle missing values\n",
        "- Remove duplicates\n",
        "- Encode categorical variables\n",
        "- Outlier detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = df.copy()\n",
        "\n",
        "missing = df_clean.isnull().sum()\n",
        "missing_pct = (missing / len(df_clean) * 100).round(2)\n",
        "pd.DataFrame({'missing_count': missing, 'missing_pct': missing_pct}).query('missing_count > 0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
        "for c in cat_cols:\n",
        "    if df_clean[c].isnull().any():\n",
        "        df_clean[c] = df_clean[c].fillna(df_clean[c].mode().iloc[0] if df_clean[c].mode().notna().any() else 'Unknown')\n",
        "\n",
        "if 'patient_id' in df_clean.columns:\n",
        "    df_clean = df_clean.drop_duplicates(subset=['patient_id'], keep='first')\n",
        "else:\n",
        "    df_clean = df_clean.drop_duplicates()\n",
        "print('After dropping duplicates:', df_clean.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
        "numeric_cols = [c for c in numeric_cols if c not in ['patient_id', 'readmitted']]\n",
        "\n",
        "def count_outliers_iqr(series):\n",
        "    Q1, Q3 = series.quantile(0.25), series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    low, high = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
        "    return ((series < low) | (series > high)).sum()\n",
        "\n",
        "outliers = {c: count_outliers_iqr(df_clean[c]) for c in numeric_cols}\n",
        "pd.Series(outliers).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cap_cols = ['time_in_hospital', 'num_lab_procedures', 'num_medications', 'number_diagnoses']\n",
        "for c in cap_cols:\n",
        "    if c in df_clean.columns:\n",
        "        q99 = df_clean[c].quantile(0.99)\n",
        "        df_clean[c] = df_clean[c].clip(upper=q99)\n",
        "print('Outliers capped at 99th percentile for:', cap_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_encoded = df_clean.copy()\n",
        "label_encoders = {}\n",
        "for c in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded[c] = le.fit_transform(df_encoded[c].astype(str))\n",
        "    label_encoders[c] = le\n",
        "print('Encoded columns:', list(label_encoders.keys()))\n",
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Exploratory Data Analysis\n",
        "\n",
        "- Readmission rate\n",
        "- Age vs readmission\n",
        "- Diagnosis vs readmission\n",
        "- Length of stay impact\n",
        "- Correlation heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "ax = axes[0, 0]\n",
        "readm_rate = df_clean['readmitted'].mean()\n",
        "ax.bar(['Not readmitted', 'Readmitted'], [1 - readm_rate, readm_rate], color=['steelblue', 'coral'])\n",
        "ax.set_ylabel('Proportion')\n",
        "ax.set_title(f'Readmission rate = {readm_rate:.2%}')\n",
        "\n",
        "ax = axes[0, 1]\n",
        "age_readm = df_clean.groupby('age')['readmitted'].mean().sort_index()\n",
        "age_readm.plot(kind='bar', ax=ax, color='teal', alpha=0.8)\n",
        "ax.set_title('Readmission rate by age group')\n",
        "ax.set_ylabel('Readmission rate')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "ax = axes[1, 0]\n",
        "diag_readm = df_clean.groupby('diag_1')['readmitted'].mean().sort_values(ascending=False)\n",
        "diag_readm.plot(kind='barh', ax=ax, color='mediumpurple', alpha=0.8)\n",
        "ax.set_title('Readmission rate by primary diagnosis')\n",
        "ax.set_xlabel('Readmission rate')\n",
        "\n",
        "ax = axes[1, 1]\n",
        "los_bins = pd.cut(df_clean['time_in_hospital'], bins=[0, 3, 5, 7, 14], labels=['1-3', '4-5', '6-7', '8+'])\n",
        "los_readm = df_clean.assign(los_bin=los_bins).groupby('los_bin')['readmitted'].mean()\n",
        "los_readm.plot(kind='bar', ax=ax, color='darkorange', alpha=0.8)\n",
        "ax.set_title('Readmission rate by length of stay (days)')\n",
        "ax.set_ylabel('Readmission rate')\n",
        "ax.set_xlabel('Length of stay')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_for_corr = df_encoded.select_dtypes(include=[np.number]).columns.tolist()\n",
        "corr = df_encoded[num_for_corr].corr()\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(corr, annot=False, cmap='RdBu_r', center=0, vmin=-0.5, vmax=0.5)\n",
        "plt.title('Correlation heatmap (encoded + numeric features)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Feature Engineering\n",
        "\n",
        "- Create risk score features\n",
        "- Convert admission dates\n",
        "- Binning age groups\n",
        "- Chronic condition indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_fe = df_clean.copy()\n",
        "\n",
        "if 'admission_date' in df_fe.columns:\n",
        "    df_fe['admission_date'] = pd.to_datetime(df_fe['admission_date'], errors='coerce')\n",
        "    df_fe['admission_month'] = df_fe['admission_date'].dt.month\n",
        "    df_fe['admission_dayofweek'] = df_fe['admission_date'].dt.dayofweek\n",
        "    df_fe['admission_weekend'] = (df_fe['admission_dayofweek'] >= 5).astype(int)\n",
        "\n",
        "age_order = ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)']\n",
        "df_fe['age_group_idx'] = df_fe['age'].map(lambda x: age_order.index(x) if x in age_order else -1).clip(0, 9)\n",
        "\n",
        "chronic_cols = [c for c in ['diabetes', 'hypertension', 'chronic_kidney_disease', 'heart_failure'] if c in df_fe.columns]\n",
        "df_fe['chronic_count'] = df_fe[chronic_cols].sum(axis=1)\n",
        "\n",
        "df_fe['risk_heuristic'] = (\n",
        "    (df_fe['time_in_hospital'] >= 7).astype(int) * 2 +\n",
        "    (df_fe['num_medications'] >= 15).astype(int) * 1 +\n",
        "    (df_fe['number_diagnoses'] >= 8).astype(int) * 1 +\n",
        "    df_fe['chronic_count']\n",
        ")\n",
        "\n",
        "print('New features:', [c for c in df_fe.columns if c not in df_clean.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_cols_fe = df_fe.select_dtypes(include=['object']).columns.tolist()\n",
        "df_model = df_fe.copy()\n",
        "for c in cat_cols_fe:\n",
        "    df_model[c] = LabelEncoder().fit_transform(df_model[c].astype(str))\n",
        "\n",
        "feature_cols = [c for c in df_model.columns if c not in ['patient_id', 'readmitted', 'admission_date']]\n",
        "X = df_model[feature_cols]\n",
        "y = df_model['readmitted']\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Features:', feature_cols[:15], '...' if len(feature_cols) > 15 else '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Model Building\n",
        "\n",
        "- Train-test split\n",
        "- Cross-validation\n",
        "- Logistic Regression, Random Forest, XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=12, random_state=42, class_weight='balanced'),\n",
        "}\n",
        "\n",
        "print('Cross-validation (F1 weighted):')\n",
        "for name, model in models.items():\n",
        "    if name == 'Logistic Regression':\n",
        "        scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='f1_weighted')\n",
        "    else:\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1_weighted')\n",
        "    print(f'  {name}: {scores.mean():.4f} (+/- {scores.std()*2:.4f})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import xgboost as xgb\n",
        "    xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=6, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "    scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='f1_weighted')\n",
        "    print(f'  XGBoost: {scores.mean():.4f} (+/- {scores.std()*2:.4f})')\n",
        "    models['XGBoost'] = xgb_model\n",
        "except ImportError:\n",
        "    print('XGBoost not installed; skipping.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=42, class_weight='balanced')\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "if 'XGBoost' in models:\n",
        "    models['XGBoost'].fit(X_train, y_train)\n",
        "print('Models fitted.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Model Evaluation\n",
        "\n",
        "Accuracy, Precision, Recall, F1, ROC-AUC, Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred, y_proba=None):\n",
        "    return {\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'F1': f1_score(y_true, y_pred, zero_division=0),\n",
        "        'ROC-AUC': roc_auc_score(y_true, y_proba[:, 1]) if y_proba is not None else None\n",
        "    }\n",
        "\n",
        "results = []\n",
        "\n",
        "y_pred_lr = lr.predict(X_test_scaled)\n",
        "y_proba_lr = lr.predict_proba(X_test_scaled)\n",
        "results.append(evaluate_model('Logistic Regression', y_test, y_pred_lr, y_proba_lr))\n",
        "\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_proba_rf = rf.predict_proba(X_test)\n",
        "results.append(evaluate_model('Random Forest', y_test, y_pred_rf, y_proba_rf))\n",
        "\n",
        "if 'XGBoost' in models:\n",
        "    y_pred_xgb = models['XGBoost'].predict(X_test)\n",
        "    y_proba_xgb = models['XGBoost'].predict_proba(X_test)\n",
        "    results.append(evaluate_model('XGBoost', y_test, y_pred_xgb, y_proba_xgb))\n",
        "\n",
        "metrics_df = pd.DataFrame(results)\n",
        "metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Classification report (Random Forest):')\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['Not readmitted', 'Readmitted']))\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "            xticklabels=['Not readmitted', 'Readmitted'],\n",
        "            yticklabels=['Not readmitted', 'Readmitted'])\n",
        "ax.set_ylabel('True')\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_title('Confusion Matrix (Random Forest)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba_lr[:, 1], name='Logistic Regression', ax=ax)\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba_rf[:, 1], name='Random Forest', ax=ax)\n",
        "if 'XGBoost' in models:\n",
        "    RocCurveDisplay.from_predictions(y_test, y_proba_xgb[:, 1], name='XGBoost', ax=ax)\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_title('ROC curves')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imp = pd.DataFrame({'feature': feature_cols, 'importance': rf.feature_importances_})\n",
        "imp = imp.sort_values('importance', ascending=False)\n",
        "imp.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "top_n = 20\n",
        "imp_top = imp.head(top_n)\n",
        "plt.barh(range(len(imp_top)), imp_top['importance'].values, color='steelblue', alpha=0.8)\n",
        "plt.yticks(range(len(imp_top)), imp_top['feature'].values)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xlabel('Feature importance (Random Forest)')\n",
        "plt.title('Top 20 features')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Business Interpretation\n",
        "\n",
        "- **High-risk patient identification**: Use model probability (e.g., >0.3 or top decile) to flag patients for enhanced discharge planning and follow-up.\n",
        "- **Risk segmentation**: Segment into Low / Medium / High risk based on predicted probability thresholds; allocate case management resources accordingly.\n",
        "- **Operational recommendations**:\n",
        "  1. Integrate risk score into discharge workflow (checklist, follow-up scheduling).\n",
        "  2. Prioritize post-discharge calls and home visits for high-risk patients.\n",
        "  3. Focus on modifiable drivers (medication reconciliation, primary care follow-up) highlighted by feature importance.\n",
        "  4. Monitor readmission rates by segment to validate model and adjust thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prob_rf = y_proba_rf[:, 1]\n",
        "df_test = pd.DataFrame({'y_true': y_test.values, 'prob': prob_rf})\n",
        "df_test['segment'] = pd.cut(prob_rf, bins=[0, 0.2, 0.4, 1.0], labels=['Low', 'Medium', 'High'])\n",
        "segment_summary = df_test.groupby('segment').agg(\n",
        "    count=('prob', 'count'),\n",
        "    actual_readmission_rate=('y_true', 'mean')\n",
        ").round(4)\n",
        "segment_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. Deployment Consideration\n",
        "\n",
        "- **How the hospital can use this model**:\n",
        "  - **Real-time**: At discharge, run the model on current encounter features and attach a risk score to the record; trigger alerts for high-risk patients.\n",
        "  - **Batch**: Daily or weekly batch scoring of recent discharges to generate lists for care managers.\n",
        "  - **Dashboard**: Show readmission risk distribution and trends; drill-down by unit, diagnosis, or physician.\n",
        "\n",
        "- **Monitoring strategy**:\n",
        "  1. **Performance**: Track precision/recall and ROC-AUC on a holdout or recent period; set alerts for drift (e.g., AUC drop > 0.05).\n",
        "  2. **Data drift**: Monitor distributions of key inputs (e.g., time_in_hospital, num_medications) and retrain if they shift substantially.\n",
        "  3. **Outcomes**: Compare actual 30-day readmission rates by risk segment to validate that high-risk segment has higher observed rate.\n",
        "  4. **Fairness**: Stratify metrics by age, race, and payer to ensure no unintended bias; recalibrate or constrain model if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Project complete. Summary:')\n",
        "print(f'  - Dataset: {len(df)} rows, readmission rate {y.mean():.2%}')\n",
        "print(f'  - Best F1 (from metrics): {metrics_df[\"F1\"].max():.4f}')\n",
        "print('  - Next steps: Export model (e.g. joblib), build API or batch job, set up monitoring.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
